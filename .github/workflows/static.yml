name: Update Heathcliff Comic

on:
  schedule:
    - cron: "0 8 * * *"      # daily 08:00 UTC
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: true

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - run: pip install requests beautifulsoup4

      - name: Fetch today's comic and build site
        run: |
          python << 'EOF'
          import requests, os
          from bs4 import BeautifulSoup
          url = "https://www.gocomics.com/heathcliff"
          r = requests.get(url, timeout=30); r.raise_for_status()
          soup = BeautifulSoup(r.text, "html.parser")
          img = soup.select_one("picture.item-comic-image img") or soup.select_one('img[itemprop="image"]')
          if not img: raise SystemExit("Comic image not found")
          img_url = img.get("src") or img.get("data-src") or ""
          if not img_url.startswith("http"): img_url = "https:" + img_url
          data = requests.get(img_url, timeout=30).content
          os.makedirs("public", exist_ok=True)
          open("public/comic.jpg","wb").write(data)
          open("public/index.html","w").write(
            '<!doctype html><meta charset="utf-8"><title>Heathcliff</title>'
            '<img src="comic.jpg" style="width:100%;height:auto">'
          )
          EOF

      - uses: actions/configure-pages@v5
      - uses: actions/upload-pages-artifact@v3
        with:
          path: public

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - id: deployment
        uses: actions/deploy-pages@v4
